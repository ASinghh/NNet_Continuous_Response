{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets fit a NNet model for continuous variable, \n",
    "\n",
    "\n",
    "data1 = pd.read_csv(\"red-wine.csv\") ## read data\n",
    "data2 = data1.loc[[356]]\n",
    "data = data1.append(data2) # making data 1600 columns for ease of split\n",
    "\n",
    "\n",
    "train, test = train_test_split(data, test_size= 2/16) ## splitting data into train and test\n",
    "\n",
    "X = train.drop(\"quality\",1).values                       ##########\n",
    "Y = np.reshape(train[\"quality\"].values,(1400,1))         #####\n",
    "X_test = test.drop(\"quality\",1).values                   #####       BUNCH OF DATA STRUCTURE MANIPULATION\n",
    "Y_test = np.reshape(test[\"quality\"].values,(200,1))      ##########\n",
    "\n",
    "batch_size = 200\n",
    "size = batch_size\n",
    "\n",
    "cursor = 0\n",
    "\n",
    "def feed(batch_size):                                       ################ Function to feed batches of data\n",
    "    assert size%batch_size == 0 ##to make sure perfect allocation of data\n",
    "    global cursor\n",
    "    x_train = X[cursor:cursor+batch_size]\n",
    "    y_train = Y[cursor:cursor+batch_size]\n",
    "    if cursor == size  :\n",
    "        cursor = 0\n",
    "    else :\n",
    "        cursor += batch_size\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, 11))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size,1 ))\n",
    "    \n",
    "    tf_test_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(200, 11))\n",
    "    tf_test_labels = tf.placeholder(tf.float32, shape=(batch_size,1 ))\n",
    "    \n",
    "    \n",
    "    weights1 = tf.Variable(\n",
    "    tf.truncated_normal([11, 32 ]))\n",
    "    biases1 = tf.Variable(tf.zeros([32]))\n",
    "    weights2 = tf.Variable(\n",
    "    tf.truncated_normal([32,1 ]))\n",
    "    biases2 = tf.Variable(tf.zeros([1]))\n",
    "    # Training computation.\n",
    "    logits1 = tf.matmul(tf_train_dataset, weights1) + biases1\n",
    "    relu1 =  tf.nn.relu(logits1)\n",
    "    logits2 = tf.matmul(relu1, weights2) + biases2\n",
    "\n",
    "    loss = tf.losses.mean_squared_error(labels=tf_train_labels, predictions=logits2,weights=1.0) \n",
    "    optimizer = tf.train.AdagradOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    tlogits1 = tf.matmul(tf_test_dataset, weights1) + biases1\n",
    "    trelu1 =  tf.nn.relu(logits1)\n",
    "    tlogits2 = tf.matmul(relu1, weights2) + biases2\n",
    "\n",
    "    tloss = tf.losses.mean_squared_error(labels=tf_test_labels, predictions=tlogits2,weights=1.0) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss(MSE) at step 0: 15281.459961\n",
      "test loss(MSE) at step 0: 15276.865234\n",
      "Minibatch loss(MSE) at step 20000: 0.439228\n",
      "test loss(MSE) at step 20000: 1.192688\n",
      "Minibatch loss(MSE) at step 40000: 0.358429\n",
      "test loss(MSE) at step 40000: 1.103507\n",
      "Minibatch loss(MSE) at step 60000: 0.337588\n",
      "test loss(MSE) at step 60000: 1.073454\n",
      "Minibatch loss(MSE) at step 80000: 0.326294\n",
      "test loss(MSE) at step 80000: 1.055665\n",
      "Minibatch loss(MSE) at step 100000: 0.319310\n",
      "test loss(MSE) at step 100000: 1.044339\n",
      "Minibatch loss(MSE) at step 120000: 0.314602\n",
      "test loss(MSE) at step 120000: 1.036888\n",
      "Minibatch loss(MSE) at step 140000: 0.311225\n",
      "test loss(MSE) at step 140000: 1.031749\n",
      "Minibatch loss(MSE) at step 160000: 0.308663\n",
      "test loss(MSE) at step 160000: 1.028153\n",
      "Minibatch loss(MSE) at step 180000: 0.306523\n",
      "test loss(MSE) at step 180000: 1.025730\n",
      "Minibatch loss(MSE) at step 200000: 0.304812\n",
      "test loss(MSE) at step 200000: 1.023852\n",
      "Minibatch loss(MSE) at step 220000: 0.303359\n",
      "test loss(MSE) at step 220000: 1.022455\n",
      "Minibatch loss(MSE) at step 240000: 0.302159\n",
      "test loss(MSE) at step 240000: 1.021392\n",
      "Minibatch loss(MSE) at step 260000: 0.301130\n",
      "test loss(MSE) at step 260000: 1.020804\n",
      "Minibatch loss(MSE) at step 280000: 0.300216\n",
      "test loss(MSE) at step 280000: 1.020270\n"
     ]
    }
   ],
   "source": [
    "num_steps = 300000\n",
    "with tf.Session(graph=graph) as session:\n",
    "    \n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        \n",
    "        batch_data, batch_labels = feed(batch_size)\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels,tf_test_dataset : X_test, tf_test_labels : Y_test}\n",
    "        _, l , j = session.run([optimizer, loss,tloss], feed_dict=feed_dict)\n",
    "        if (step % 20000 == 0):\n",
    "            print(\"Minibatch loss(MSE) at step %d: %f\" % (step, l))\n",
    "            print(\"test loss(MSE) at step %d: %f\" % (step, j))\n",
    "        \n",
    "\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
